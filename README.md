# ğŸš€ ELT Pipeline com Snowflake + dbt + Python

## ğŸ“Œ VisÃ£o Geral do Projeto

Este projeto implementa um pipeline **ELT (Extractâ€“Loadâ€“Transform)** completo para ingestÃ£o, armazenamento e transformaÃ§Ã£o de dados de vagas de trabalho remoto.

Fluxo geral do pipeline (conforme arquitetura do projeto):

1. **ExtraÃ§Ã£o (E)** â€“ Dados sÃ£o coletados da API pÃºblica da **Jobicy** via scripts em Python.
2. **Load (L)** â€“ Os dados brutos sÃ£o carregados no **Snowflake** como tabela de origem (raw).
3. **TransformaÃ§Ã£o (T)** â€“ Modelagens analÃ­ticas sÃ£o realizadas no **dbt Core**, gerando tabelas tratadas (camada silver) prontas para anÃ¡lise.

---

## ğŸ—ï¸ Arquitetura

![Arquitetura ELT](docs/architecture.png)

ğŸ”¹ **Componentes principais:**

* **Jobicy API** â€“ Fonte de dados de vagas remotas
* **Python** â€“ ResponsÃ¡vel por extrair e carregar os dados no Snowflake
* **Snowflake** â€“ Data warehouse onde os dados sÃ£o armazenados
* **dbt Core** â€“ Ferramenta de transformaÃ§Ã£o e modelagem dos dados

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```
elt_dbt/
â”œâ”€â”€ extraction/           # Scripts de extraÃ§Ã£o e carga (Python)
â”‚   â”œâ”€â”€ script.py
â”‚   â”œâ”€â”€ script_v2.py
â”‚   â””â”€â”€ script_v3.py
â”‚
â”œâ”€â”€ dbt_elt/              # Projeto dbt
â”‚   â”œâ”€â”€ models/           # Modelos SQL (transformaÃ§Ãµes)
â”‚   â”‚   â””â”€â”€ example/
â”‚   â”‚       â””â”€â”€ silver/
â”‚   â”‚           â””â”€â”€ trabalho_remoto.sql
â”‚   â”œâ”€â”€ seeds/
â”‚   â”œâ”€â”€ snapshots/
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ profiles.yml
â”‚
â”œâ”€â”€ pyproject.toml        # DependÃªncias do projeto (Poetry)
â”œâ”€â”€ poetry.lock           # Lockfile de dependÃªncias
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Como Executar o Projeto

### 1ï¸âƒ£ Instalar dependÃªncias

Certifique-se de ter **Python 3.9+** e **Poetry** instalados.

```bash
poetry install
```

### 2ï¸âƒ£ Executar a extraÃ§Ã£o e carga no Snowflake

```bash
python extraction/script_v3.py
```

> âš ï¸ Antes de rodar, configure suas credenciais do Snowflake no arquivo `profiles.yml`.

### 3ï¸âƒ£ Rodar transformaÃ§Ãµes no dbt

```bash
cd dbt_elt
dbt run
```

### 4ï¸âƒ£ (Opcional) Rodar testes de qualidade de dados

```bash
dbt test
```

---

## ğŸ§  Modelo de Dados (Camada Silver)

O modelo principal gerado pelo dbt Ã©:

* **trabalho_remoto** â€“ tabela tratada contendo:

  * tÃ­tulo da vaga
  * nome da empresa
  * salÃ¡rio mÃ­nimo e mÃ¡ximo anual
  * salÃ¡rio mensal calculado

Essa tabela estÃ¡ pronta para consumo por ferramentas de BI ou anÃ¡lises avanÃ§adas.

---

## ğŸ¯ PrÃ³ximos Passos (Roadmap)

Algumas melhorias planejadas para versÃµes futuras:

* âœ”ï¸ Implementar testes de qualidade de dados no dbt (data tests)
* ğŸ”„ Criar carregamento incremental no Snowflake
* ğŸ¤– Automatizar o pipeline com GitHub Actions
* ğŸ“Š Criar dashboards no Power BI ou Tableau

---


ğŸ“ GitHub: [https://github.com/renataennes](https://github.com/renataennes)

